{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 4 - Performance Metrics\n",
    "\n",
    "In this workshop we study 2 performance metrics(Spread and Inter-Generational Distance) on GA optimizing the POM3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# All the imports\n",
    "from __future__ import print_function, division\n",
    "import pom3_ga, sys\n",
    "import pickle, math\n",
    "\n",
    "# TODO 1: Enter your unity ID here \n",
    "__author__ = \"mumesha\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute most measures, data(i.e objectives) is normalized. Normalization is scaling the data between 0 and 1. Why do we normalize?\n",
    "\n",
    "TODO2 : To make it easier to compare measures with different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(problem, points):\n",
    "  \"\"\"\n",
    "  Normalize all the objectives\n",
    "  in each point and return them\n",
    "  \"\"\"\n",
    "  meta = problem.objectives\n",
    "  all_objs = []\n",
    "  for point in points:\n",
    "    objs = []\n",
    "    for i, o in enumerate(problem.evaluate(point)):\n",
    "      low, high = meta[i].low, meta[i].high\n",
    "      # TODO 3: Normalize 'o' between 'low' and 'high'; Then add the normalized value to 'objs'\n",
    "      if high == low: objs.append(0); continue;\n",
    "      objs.append((o-low)/(high-low))  \n",
    "    all_objs.append(objs)\n",
    "  return all_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Format\n",
    "For our experiments we store the data in the following format.\n",
    "```\n",
    "data = {\n",
    "            \"expt1\":[repeat1, repeat2, ...], \n",
    "            \"expt2\":[repeat1, repeat2, ...], \n",
    "            .\n",
    "            .\n",
    "            .\n",
    "       }\n",
    "repeatx = [objs1, objs2, ....]     // All of the final population\n",
    "objs1 = [norm_obj1, norm_obj2, ...] // Normalized objectives of each member of the final population.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 50, 5]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performing experiments for [5, 10, 50] generations.\n",
    "\"\"\"\n",
    "problem = pom3_ga.POM3()\n",
    "pop_size = 10\n",
    "repeats = 10\n",
    "test_gens = [5, 10, 50]\n",
    "\n",
    "def save_data(file_name, data):\n",
    "  \"\"\"\n",
    "  Save 'data' to 'file_name.pkl'\n",
    "  \"\"\"\n",
    "  with open(file_name + \".pkl\", 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def load_data(file_name):\n",
    "  \"\"\"\n",
    "  Retrieve data from 'file_name.pkl'\n",
    "  \"\"\"\n",
    "  with open(file_name + \".pkl\", 'rb') as f:\n",
    "    return pickle.load(f)\n",
    "\n",
    "def build(problem, pop_size, repeats, test_gens):\n",
    "  \"\"\"\n",
    "  Repeat the experiment for 'repeats' number of repeats for each value in 'test_gens'\n",
    "  \"\"\"\n",
    "  tests = {t: [] for t in test_gens}\n",
    "  tests[0] = [] # For Initial Population\n",
    "  for _ in range(repeats):\n",
    "    init_population = pom3_ga.populate(problem, pop_size)\n",
    "    pom3_ga.say(\".\")\n",
    "    for gens in test_gens:\n",
    "      tests[gens].append(normalize(problem, pom3_ga.ga(problem, init_population, retain_size=pop_size, gens=gens)[1]))\n",
    "    tests[0].append(normalize(problem, init_population))\n",
    "  print(\"\\nCompleted\")\n",
    "  return tests\n",
    "\n",
    "\"\"\"\n",
    "Repeat Experiments\n",
    "\"\"\"\n",
    "# tests = build(problem, pop_size, repeats, test_gens)\n",
    "\n",
    "\"\"\"\n",
    "Save Experiment Data into a file\n",
    "\"\"\"\n",
    "# save_data(\"dump\", tests)\n",
    "\n",
    "\"\"\"\n",
    "Load the experimented data from dump.\n",
    "\"\"\"\n",
    "tests = load_data(\"dump\")\n",
    "print(tests.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Set\n",
    "Almost all the traditional measures you consider need a reference set for its computation. A theoritical reference set would be the ideal pareto frontier. This is fine for \n",
    "a) Mathematical Models: Where we can solve the problem to obtain the set.\n",
    "b) Low Runtime Models: Where we can do a one time exaustive run to obtain the model.\n",
    "\n",
    "But most real world problems are neither mathematical nor have a low runtime. So what do we do?. **Compute an approximate reference set**\n",
    "\n",
    "One possible way of constructing it is:\n",
    "1. Take the final generation of all the treatments.\n",
    "2. Select the best set of solutions from all the final generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.018667164751246072, 0.6725435355538931, 1.0, 0.0],\n",
       " [0.03236982922166506, 0.8929704175715291, 1.0, 0.0],\n",
       " [0.012577365172705437, 0.5902742693038511, 0.9166666666666666, 0.0],\n",
       " [0.031970980789334746, 0.6408347041400978, 0.8947368421052632, 0.0],\n",
       " [0.02095599670188364, 0.6778384360925239, 0.7857142857142857, 0.0],\n",
       " [0.07765335322416529, 0.5706053874436364, 0.8695652173913043, 0.0],\n",
       " [0.09958142712660678, 0.772687573987016, 0.6884057971014492, 0.0],\n",
       " [0.08738234913396675, 0.653748187881778, 0.712707182320442, 0.0],\n",
       " [0.06966259780901314,\n",
       "  0.5721201437854408,\n",
       "  0.9736842105263158,\n",
       "  0.22916666666666663],\n",
       " [0.05191147906812763, 0.49380105682129466, 1.0, 0.0]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_reference(problem, *fronts):\n",
    "  \"\"\"\n",
    "  Make a reference set comparing all the fronts.\n",
    "  Here the comparison we use is bdom. It can\n",
    "  be altered to use cdom as well\n",
    "  \"\"\"\n",
    "  retain_size = len(fronts[0])\n",
    "  reference = []\n",
    "  for front in fronts:\n",
    "    reference+=front\n",
    "\n",
    "  def bdom(one, two):\n",
    "    \"\"\"\n",
    "    Return True if 'one' dominates 'two'\n",
    "    else return False\n",
    "    :param one - [pt1_obj1, pt1_obj2, pt1_obj3, pt1_obj4]\n",
    "    :param two - [pt2_obj1, pt2_obj2, pt2_obj3, pt2_obj4]\n",
    "    \"\"\"\n",
    "    dominates = False\n",
    "    for i, obj in enumerate(problem.objectives):\n",
    "      gt, lt = pom3_ga.gt, pom3_ga.lt\n",
    "      better = lt if obj.do_minimize else gt\n",
    "      # TODO 3: Use the varaibles declared above to check if one dominates two\n",
    "      if better(one[i],two[i]):\n",
    "         dominates = True\n",
    "      elif one[i] != two[i]:\n",
    "        return False\n",
    "    return dominates\n",
    "  \n",
    "  def fitness(one, dom):\n",
    "    return len([1 for another in reference if dom(one, another)])\n",
    "  \n",
    "  fitnesses = []\n",
    "  for point in reference:\n",
    "    fitnesses.append((fitness(point, bdom), point))\n",
    "  reference = [tup[1] for tup in sorted(fitnesses, reverse=True)]\n",
    "  return reference[:retain_size]\n",
    "    \n",
    "make_reference(problem, tests[5][0], tests[10][0], tests[50][0])\n",
    "#assert len(make_reference(problem, tests[5][0], tests[10][0], tests[50][0])) == len(tests[5][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread\n",
    "\n",
    "Calculating spread: \n",
    "\n",
    "<img width=300 src=\"http://mechanicaldesign.asmedigitalcollection.asme.org/data/Journals/JMDEDB/27927/022006jmd3.jpeg\">\n",
    "\n",
    "- Consider the population of final gen(P) and the Pareto Frontier(R).\n",
    "- Find the distances between the first point of P and first point of R(_d<sub>f</sub>_) and last point of P and last point of R(_d<sub>l</sub>_)\n",
    "- Find the distance between all points and their nearest neighbor _d<sub>i</sub>_ and\n",
    "  their nearest neighbor\n",
    "  - Then:\n",
    "  \n",
    "<img width=300 src=\"https://raw.githubusercontent.com/txt/ase16/master/img/spreadcalc.png\">\n",
    "\n",
    "- If all data is maximally spread, then all distances _d<sub>i</sub>_ are near mean d\n",
    "which would make _&Delta;=0_ ish.\n",
    "\n",
    "Note that _less_ the spread of each point to its neighbor, the _better_\n",
    "since this means the optimiser is offering options across more of the frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.336453190893\n",
      "0.478501820094\n",
      "0.38318665997\n"
     ]
    }
   ],
   "source": [
    "def eucledian(one, two):\n",
    "  \"\"\"\n",
    "  Compute Eucledian Distance between\n",
    "  2 vectors. We assume the input vectors\n",
    "  are normalized.\n",
    "  :param one: Vector 1\n",
    "  :param two: Vector 2\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  # TODO 4: Code up the eucledian distance. https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "  dist = 0\n",
    "  #dist = math.sqrt(sum([(x-y)**2 for x,y in zip(one,two)]) / len(one)) -- use if data not normalized\n",
    "  dist = math.sqrt(sum([(x-y)**2 for x,y in zip(one,two)]))  \n",
    "  return dist\n",
    "\n",
    "def sort_solutions(solutions):\n",
    "  \"\"\"\n",
    "  Sort a list of list before computing spread\n",
    "  \"\"\"\n",
    "  def sorter(lst):\n",
    "    m = len(lst)\n",
    "    weights = reversed([10 ** i for i in xrange(m)])\n",
    "    return sum([element * weight for element, weight in zip(lst, weights)])\n",
    "  return sorted(solutions, key=sorter)\n",
    "\n",
    "\n",
    "def closest(one, many):\n",
    "  min_dist = sys.maxint\n",
    "  closest_point = None\n",
    "  for this in many:\n",
    "    dist = eucledian(this, one)\n",
    "    if dist < min_dist:\n",
    "      min_dist = dist\n",
    "      closest_point = this\n",
    "  return min_dist, closest_point\n",
    "\n",
    "def spread(obtained, ideals):\n",
    "  \"\"\"\n",
    "  Calculate the spread (a.k.a diversity)\n",
    "  for a set of solutions\n",
    "  \"\"\"\n",
    "  s_obtained = sort_solutions(obtained)\n",
    "  s_ideals = sort_solutions(ideals)\n",
    "  d_f = closest(s_ideals[0], s_obtained)[0]\n",
    "  d_l = closest(s_ideals[-1], s_obtained)[0]\n",
    "  n = len(s_ideals)\n",
    "  distances = []\n",
    "  for i in range(len(s_obtained)-1):\n",
    "    distances.append(eucledian(s_obtained[i], s_obtained[i+1]))\n",
    "  d_bar = sum(distances)/len(distances)\n",
    "  # TODO 5: Compute the value of spread using the definition defined in the previous cell.\n",
    "  d_sum = sum([abs(d_i-d_bar) for d_i in distances])\n",
    "  delta = (d_l + d_f + d_sum) / (d_f + d_l + (n-1)*d_bar)\n",
    "  return delta\n",
    "\n",
    "\n",
    "ref = make_reference(problem, tests[5][0], tests[10][0], tests[50][0])\n",
    "\n",
    "print(spread(tests[5][0], ref))\n",
    "print(spread(tests[10][0], ref))\n",
    "print(spread(tests[50][0], ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IGD = inter-generational distance; i.e. how good are you compared to the _best known_?\n",
    "\n",
    "- Find a _reference set_ (the best possible solutions)\n",
    "- For each optimizer\n",
    "      - For each item in its final Pareto frontier\n",
    "      - Find the nearest item in the reference set and compute the distance to it.\n",
    "      - Take the mean of all the distances. This is IGD for the optimizer\n",
    "\n",
    "Note that the _less_ the mean IGD, the _better_ the optimizer since\n",
    "this means its solutions are closest to the best of the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.122495035761\n",
      "0.122223838857\n",
      "0.0751191674685\n"
     ]
    }
   ],
   "source": [
    "def igd(obtained, ideals):\n",
    "  \"\"\"\n",
    "  Compute the IGD for a\n",
    "  set of solutions\n",
    "  :param obtained: Obtained pareto front\n",
    "  :param ideals: Ideal pareto front\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  # TODO 6: Compute the value of IGD using the definition defined in the previous cell.\n",
    "  igd_val = sum([closest(ideal,obtained)[0] for ideal in ideals]) / len(ideals)\n",
    "  return igd_val\n",
    "\n",
    "ref = make_reference(problem, tests[5][0], tests[10][0], tests[50][0])\n",
    "\n",
    "print(igd(tests[5][0], ref))\n",
    "print(igd(tests[10][0], ref))\n",
    "print(igd(tests[50][0], ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IGD ***\n",
      "rank ,                   name ,    med   ,  iqr \n",
      "----------------------------------------------------\n",
      "1 ,                gens_50 ,    5 ,    2 \n",
      "2 ,                gens_10 ,    9 ,    2 \n",
      "2 ,                 gens_5 ,    9 ,    3 \n",
      "3 ,                 gens_0 ,   18 ,    3 \n",
      "\n",
      "*** Spread ***\n",
      "rank ,                   name ,    med   ,  iqr \n",
      "----------------------------------------------------\n",
      "1 ,                 gens_0 ,   37 ,    6 \n",
      "2 ,                 gens_5 ,   42 ,   18 \n",
      "2 ,                gens_10 ,   43 ,    7 \n",
      "2 ,                gens_50 ,   46 ,   16 \n"
     ]
    }
   ],
   "source": [
    "import sk\n",
    "sk = reload(sk)\n",
    "\n",
    "def format_for_sk(problem, data, measure):\n",
    "  \"\"\"\n",
    "  Convert the experiment data into the format\n",
    "  required for sk.py and computet the desired\n",
    "  'measure' for all the data.\n",
    "  \"\"\"\n",
    "  gens = data.keys()\n",
    "  reps = len(data[gens[0]])\n",
    "  measured = {gen:[\"gens_%d\"%gen] for gen in gens}\n",
    "  for i in range(reps):\n",
    "    ref_args = [data[gen][i] for gen in gens]\n",
    "    ref = make_reference(problem, *ref_args)\n",
    "    for gen in gens:\n",
    "      measured[gen].append(measure(data[gen][i], ref))\n",
    "  return measured\n",
    "\n",
    "def report(problem, tests, measure):\n",
    "  measured = format_for_sk(problem, tests, measure).values()\n",
    "  sk.rdivDemo(measured)\n",
    "    \n",
    "print(\"*** IGD ***\")\n",
    "report(problem, tests, igd)\n",
    "print(\"\\n*** Spread ***\")\n",
    "report(problem, tests, spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
